#!/usr/bin/env python3
"""
ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ìš” ê¸ˆìœµ ì´ìŠˆë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ê³  ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import os
import requests
import json
import time
from datetime import datetime
from dotenv import load_dotenv

# API í‚¤ ë¡œë“œ
load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')

def call_openai(question, context="", max_tokens=1000, system_prompt=None):
    """OpenAI API í˜¸ì¶œ"""
    api_url = 'https://api.openai.com/v1/chat/completions'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    if system_prompt is None:
        system_prompt = 'ë‹¹ì‹ ì€ ê¸ˆìœµ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ì‹¤ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.'
    
    user_message = f"{context}\n\n{question}" if context else question
    
    payload = {
        'model': 'gpt-4o',
        'messages': [
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': user_message}
        ],
        'max_tokens': max_tokens,
        'temperature': 0.3
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            return f"API ì˜¤ë¥˜ (ì½”ë“œ {response.status_code}): {response.text}"
    except Exception as e:
        return f"ì˜ˆì™¸ ë°œìƒ: {str(e)}"

def load_news_data(filepath):
    """ë‰´ìŠ¤ ë¡œê·¸ íŒŒì¼ ì½ê¸°"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except Exception as e:
        print(f"ë‰´ìŠ¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def extract_key_issues(news_content):
    """ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì—ì„œ ì£¼ìš” ì´ìŠˆì™€ ë¶„ì„ ì§ˆë¬¸ì„ ìë™ ìƒì„± (ê¸€ë¡œë²Œ/í•œêµ­, ë§¤í¬ë¡œ/ê¸°ì—… ë¶„ë¥˜)"""
    print("\n[1ë‹¨ê³„] ë‰´ìŠ¤ ë°ì´í„°ì—ì„œ ì£¼ìš” ì´ìŠˆ ì¶”ì¶œ ì¤‘...")
    print("  - ê¸€ë¡œë²Œ ì´ìŠˆ: ë§¤í¬ë¡œ 5ê°œ + ê¸°ì—… 15ê°œ = 20ê°œ")
    print("  - í•œêµ­ ì´ìŠˆ: ë§¤í¬ë¡œ 5ê°œ + ê¸°ì—… 15ê°œ = 20ê°œ")
    print("  - ì´ 40ê°œ ì´ìŠˆ ì¶”ì¶œ ì˜ˆì •\n")
    
    # ë‰´ìŠ¤ ì „ì²´ ì‚¬ìš© (ì¶©ë¶„í•œ ìƒ˜í”Œ)
    news_sample = news_content[:30000] if len(news_content) > 30000 else news_content
    
    prompt = """ë‹¤ìŒì€ ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ìˆ˜ì§‘ëœ ê¸ˆìœµ ë‰´ìŠ¤ì…ë‹ˆë‹¤.

ì´ ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì—¬ ì´ 40ê°œì˜ ì£¼ìš” ì´ìŠˆë¥¼ ë‹¤ìŒ ì²´ê³„ë¡œ ì¶”ì¶œí•˜ì„¸ìš”:

ã€ê¸€ë¡œë²Œ ë‰´ìŠ¤ - ì´ 20ê°œã€‘
1. ë§¤í¬ë¡œ ì´ìŠˆ (5ê°œ): ê¸ˆë¦¬, í™˜ìœ¨, í†µí™”ì •ì±…, ê²½ì œì§€í‘œ, ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ë“±
2. ê¸°ì—… ì´ìŠˆ (15ê°œ): ê¸€ë¡œë²Œ ê¸°ì—…ì˜ ì‹¤ì , ì‚°ì—… íŠ¸ë Œë“œ, ê¸°ìˆ  í˜ì‹ , M&A ë“±
   - ë§ì´ ì–¸ê¸‰ëœ ì£¼ìš” ê¸°ì—… ìœ„ì£¼ë¡œ ì„ ì •í•˜ë˜
   - ëœ ì–¸ê¸‰ë˜ì§€ë§Œ ì¤‘ìš”í•œ ê¸°ì—… ì´ìŠˆë„ í¬í•¨

ã€í•œêµ­ ë‰´ìŠ¤ - ì´ 20ê°œã€‘
1. ë§¤í¬ë¡œ ì´ìŠˆ (5ê°œ): í•œêµ­ ê¸ˆë¦¬ì •ì±…, í™˜ìœ¨, ì •ë¶€ì •ì±…, ê²½ì œì§€í‘œ ë“±
2. ê¸°ì—… ì´ìŠˆ (15ê°œ): í•œêµ­ ê¸°ì—…ì˜ ì‹¤ì , ì‚°ì—… íŠ¸ë Œë“œ, ê¸°ìˆ  í˜ì‹ , M&A ë“±
   - ë§ì´ ì–¸ê¸‰ëœ ì£¼ìš” ê¸°ì—… ìœ„ì£¼ë¡œ ì„ ì •í•˜ë˜
   - ëœ ì–¸ê¸‰ë˜ì§€ë§Œ ì¤‘ìš”í•œ ê¸°ì—… ì´ìŠˆë„ í¬í•¨

ê° ì´ìŠˆì— ëŒ€í•´ 'ì™œ(Why)'ì™€ 'ì–´ë–»ê²Œ(How)'ë¥¼ ê¹Šì´ ìˆê²Œ ì¡°ì‚¬í•  ìˆ˜ ìˆëŠ” ì‹¬ì¸µ ë¶„ì„ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ JSONìœ¼ë¡œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”:
{
  "global_macro": [
    {"title": "ì´ìŠˆ ì œëª©", "question": "ì‹¬ì¸µ ë¶„ì„ ì§ˆë¬¸"}
  ],
  "global_corporate": [
    {"title": "ì´ìŠˆ ì œëª©", "question": "ì‹¬ì¸µ ë¶„ì„ ì§ˆë¬¸"}
  ],
  "korea_macro": [
    {"title": "ì´ìŠˆ ì œëª©", "question": "ì‹¬ì¸µ ë¶„ì„ ì§ˆë¬¸"}
  ],
  "korea_corporate": [
    {"title": "ì´ìŠˆ ì œëª©", "question": "ì‹¬ì¸µ ë¶„ì„ ì§ˆë¬¸"}
  ]
}

ì¤‘ìš”: 
- ì‹¤ì œë¡œ ë‰´ìŠ¤ì— ë“±ì¥í•œ ì´ìŠˆë§Œ ì„ ì •í•  ê²ƒ
- ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ê³  ë¶„ì„ ê°€ëŠ¥í•´ì•¼ í•¨
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•  ê²ƒ
- ê° ì¹´í…Œê³ ë¦¬ì˜ ê°œìˆ˜ë¥¼ ì •í™•íˆ ì§€í‚¬ ê²ƒ (ë§¤í¬ë¡œ 5ê°œ, ê¸°ì—… 15ê°œ)"""
    
    response = call_openai(
        prompt,
        context=news_sample,
        max_tokens=4000,
        system_prompt='ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë° í•œêµ­ ê¸ˆìœµì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§¤í¬ë¡œì™€ ê¸°ì—… ì´ìŠˆë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.'
    )
    
    try:
        # JSON íŒŒì‹±
        if '```json' in response:
            response = response.split('```json')[1].split('```')[0].strip()
        elif '```' in response:
            response = response.split('```')[1].split('```')[0].strip()
        
        issues_data = json.loads(response)
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì´ìŠˆ ìˆ˜ì§‘
        all_issues = []
        
        # ê¸€ë¡œë²Œ ë§¤í¬ë¡œ
        global_macro = issues_data.get('global_macro', [])
        for issue in global_macro:
            issue['category'] = 'ê¸€ë¡œë²Œ ë§¤í¬ë¡œ'
            all_issues.append(issue)
        
        # ê¸€ë¡œë²Œ ê¸°ì—…
        global_corporate = issues_data.get('global_corporate', [])
        for issue in global_corporate:
            issue['category'] = 'ê¸€ë¡œë²Œ ê¸°ì—…'
            all_issues.append(issue)
        
        # í•œêµ­ ë§¤í¬ë¡œ
        korea_macro = issues_data.get('korea_macro', [])
        for issue in korea_macro:
            issue['category'] = 'í•œêµ­ ë§¤í¬ë¡œ'
            all_issues.append(issue)
        
        # í•œêµ­ ê¸°ì—…
        korea_corporate = issues_data.get('korea_corporate', [])
        for issue in korea_corporate:
            issue['category'] = 'í•œêµ­ ê¸°ì—…'
            all_issues.append(issue)
        
        print(f"  âœ“ ê¸€ë¡œë²Œ ë§¤í¬ë¡œ: {len(global_macro)}ê°œ")
        print(f"  âœ“ ê¸€ë¡œë²Œ ê¸°ì—…: {len(global_corporate)}ê°œ")
        print(f"  âœ“ í•œêµ­ ë§¤í¬ë¡œ: {len(korea_macro)}ê°œ")
        print(f"  âœ“ í•œêµ­ ê¸°ì—…: {len(korea_corporate)}ê°œ")
        print(f"  âœ“ ì´ {len(all_issues)}ê°œ ì´ìŠˆ ì¶”ì¶œ ì™„ë£Œ\n")
        
        return all_issues
    except json.JSONDecodeError as e:
        print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"ì‘ë‹µ ë‚´ìš©: {response[:500]}...")
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìë™ ìƒì„± ì‹œì‘")
    print("="*80)
    
    # ë‰´ìŠ¤ íŒŒì¼ ì°¾ê¸° (ê°€ì¥ ìµœê·¼ íŒŒì¼)
    import glob
    news_files = glob.glob('output/news_log_*.txt')
    if not news_files:
        print("âŒ ë‰´ìŠ¤ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    latest_news_file = sorted(news_files)[-1]
    print(f"\nğŸ“‚ ë‰´ìŠ¤ íŒŒì¼: {latest_news_file}")
    
    # ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
    news_content = load_news_data(latest_news_file)
    if not news_content:
        print("âŒ ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # ì£¼ìš” ì´ìŠˆ ìë™ ì¶”ì¶œ
    analysis_topics = extract_key_issues(news_content)
    if not analysis_topics:
        print("âŒ ì£¼ìš” ì´ìŠˆ ì¶”ì¶œ ì‹¤íŒ¨")
        return
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì´ìŠˆ ê°œìˆ˜ í‘œì‹œ
    categories = {}
    for topic in analysis_topics:
        cat = topic.get('category', 'ê¸°íƒ€')
        categories[cat] = categories.get(cat, 0) + 1
    
    print("ì¹´í…Œê³ ë¦¬ë³„ ì´ìŠˆ:")
    for cat, count in categories.items():
        print(f"  - {cat}: {count}ê°œ")
    
    # ë³´ê³ ì„œ ìƒì„±
    print(f"\n[2ë‹¨ê³„] ì´ {len(analysis_topics)}ê°œ ì´ìŠˆì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
    print("="*80)
    
    report_lines = []
    report_lines.append("=" * 100)
    report_lines.append("\nğŸ“Š ê¸ˆìœµ ë‰´ìŠ¤ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ (ì²´ê³„ì  ë¶„ë¥˜)")
    report_lines.append("In-Depth Financial News Analysis Report (Systematic Classification)\n")
    report_lines.append(f"ë³´ê³ ì„œ ì‘ì„±ì¼: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}")
    report_lines.append(f"ë°ì´í„° ì†ŒìŠ¤: {latest_news_file}")
    report_lines.append("ë¶„ì„ ë°©ë²•: OpenAI GPT-4o ê¸°ë°˜ ìë™ ì´ìŠˆ ì¶”ì¶œ ë° ì‹¬ì¸µ ë¶„ì„")
    report_lines.append("ë¶„ë¥˜ ì²´ê³„: ê¸€ë¡œë²Œ/í•œêµ­ Ã— ë§¤í¬ë¡œ/ê¸°ì—…\n")
    report_lines.append("=" * 100)
    report_lines.append("\n\nã€ ë³´ê³ ì„œ ê°œìš” ã€‘\n")
    report_lines.append("ë³¸ ë³´ê³ ì„œëŠ” ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ìˆ˜ì§‘ëœ ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ AIê°€ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬,")
    report_lines.append("ì£¼ìš” ì‹œì¥ ì´ìŠˆë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ì‹¬ì¸µ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n")
    report_lines.append("ë¶„ë¥˜ ê¸°ì¤€:")
    report_lines.append("  - ê¸€ë¡œë²Œ/í•œêµ­: ì§€ì—­ë³„ êµ¬ë¶„")
    report_lines.append("  - ë§¤í¬ë¡œ/ê¸°ì—…: ì´ìŠˆ ìœ í˜•ë³„ êµ¬ë¶„")
    report_lines.append("    * ë§¤í¬ë¡œ: ê¸ˆë¦¬, í™˜ìœ¨, ì •ì±…, ê²½ì œì§€í‘œ ë“±")
    report_lines.append("    * ê¸°ì—…: ê¸°ì—… ì‹¤ì , ì‚°ì—… íŠ¸ë Œë“œ, M&A, ê¸°ìˆ  í˜ì‹  ë“±\n")
    report_lines.append(f"ì´ {len(analysis_topics)}ê°œ ì´ìŠˆ ë¶„ì„ ì™„ë£Œ\n\n")

    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¶œë ¥
    current_category = None
    for i, topic in enumerate(analysis_topics, 1):
        category = topic.get('category', 'ê¸°íƒ€')
        
        # ì¹´í…Œê³ ë¦¬ê°€ ë°”ë€” ë•Œë§ˆë‹¤ ì„¹ì…˜ í—¤ë” ì¶”ê°€
        if category != current_category:
            report_lines.append("\n" + "=" * 100)
            report_lines.append(f"\nã€ {category} ã€‘\n")
            report_lines.append("=" * 100 + "\n")
            current_category = category
        
        print(f"\n[{i}/{len(analysis_topics)}] [{category}] {topic['title']} ë¶„ì„ ì¤‘...")
        
        report_lines.append("â”" * 100)
        report_lines.append(f"\nâ–  {topic['title']}\n")
        
        analysis_result = call_openai(topic['question'])
        report_lines.append(analysis_result)
        report_lines.append("\n\n")
        
        print(f"  âœ“ ì™„ë£Œ ({len(analysis_result)} ê¸€ì)")
        
        # Rate limit ë°©ì§€ (40ê°œ ì´ìŠˆë‹ˆê¹Œ ì¡°ê¸ˆ ë” ì—¬ìœ ìˆê²Œ)
        if i < len(analysis_topics):
            time.sleep(2)

    # ì¢…í•© ì‹œì‚¬ì 
    report_lines.append("\n" + "=" * 100)
    report_lines.append("\nã€ ì¢…í•© ì‹œì‚¬ì  ã€‘\n")
    report_lines.append("=" * 100 + "\n")
    report_lines.append("ë³¸ ë³´ê³ ì„œë¥¼ í†µí•´ í˜„ì¬ ê¸ˆìœµì‹œì¥ì˜ ì£¼ìš” ë™í–¥ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n")
    report_lines.append("1. ê¸€ë¡œë²Œ ë§¤í¬ë¡œ: ì£¼ìš”êµ­ í†µí™”ì •ì±…, ê²½ì œì§€í‘œ, ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ë™í–¥")
    report_lines.append("2. ê¸€ë¡œë²Œ ê¸°ì—…: ì£¼ìš” ê¸€ë¡œë²Œ ê¸°ì—…ì˜ ì‹¤ì , ì‚°ì—… íŠ¸ë Œë“œ, ê¸°ìˆ  í˜ì‹ ")
    report_lines.append("3. í•œêµ­ ë§¤í¬ë¡œ: êµ­ë‚´ ê¸ˆë¦¬ì •ì±…, í™˜ìœ¨, ì •ë¶€ ì •ì±… ë°©í–¥")
    report_lines.append("4. í•œêµ­ ê¸°ì—…: êµ­ë‚´ ê¸°ì—… ì‹¤ì , ì‚°ì—… ë™í–¥, M&A í™œë™\n")
    report_lines.append("ê° ì´ìŠˆëŠ” ë…ë¦½ì ìœ¼ë¡œ ë°œìƒí•œ ê²ƒì´ ì•„ë‹ˆë¼, ê¸€ë¡œë²Œ ê²½ì œ í™˜ê²½, ê¸°ìˆ  ë°œì „,")
    report_lines.append("ì§€ì •í•™ì  ìš”ì¸ ë“±ì´ ë³µí•©ì ìœ¼ë¡œ ì‘ìš©í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n")
    report_lines.append("íˆ¬ììëŠ” ì´ëŸ¬í•œ ì´ìŠˆë“¤ì˜ ìƒí˜¸ ì—°ê´€ì„±ì„ ì´í•´í•˜ê³ , ì¥ê¸°ì  ê´€ì ì—ì„œ")
    report_lines.append("ì‹œì¥ ë³€í™”ë¥¼ ì£¼ì‹œí•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\n\n")

    # í‘¸í„°
    report_lines.append("=" * 100)
    report_lines.append("\nâš ï¸ ë©´ì±… ì¡°í•­")
    report_lines.append("ë³¸ ë³´ê³ ì„œëŠ” AI ê¸°ë°˜ ë¶„ì„ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, íˆ¬ì ì¡°ì–¸ì´ë‚˜ ì¢…ëª© ì¶”ì²œì´ ì•„ë‹Œ")
    report_lines.append("ì‹œì¥ ì´í•´ë¥¼ ë•ê¸° ìœ„í•œ ì •ë³´ ì œê³µ ëª©ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
    report_lines.append("ë¶„ì„ ì—”ì§„: OpenAI GPT-4o")
    report_lines.append(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
    report_lines.append(f"ë¶„ì„ ì´ìŠˆ ìˆ˜: {len(analysis_topics)}ê°œ\n")
    report_lines.append("=" * 100)

    # íŒŒì¼ ì €ì¥
    output_file = 'output/INDEPTH_ANALYSIS_REPORT.txt'
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))

    print(f"\n{'='*80}")
    print(f"âœ… ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“„ ì €ì¥ ìœ„ì¹˜: {output_file}")
    print(f"ğŸ“Š ë¶„ì„ëœ ì´ìŠˆ: {len(analysis_topics)}ê°œ")
    for cat, count in categories.items():
        print(f"   - {cat}: {count}ê°œ")
    print(f"{'='*80}")

if __name__ == '__main__':
    main()
